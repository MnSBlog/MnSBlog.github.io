---
date: 2022-09-04 22:54:00
layout: post
title: 씬 뎁스를 이용한 포인터 클라우드 디스플레이 
subtitle: Displaying a Point Cloud Using Scene Depth
description: Present a visualization of the physical environment by placing points based a scene’s depth data.
image: https://cdn.jsdelivr.net/gh/MnSBlog/MnSBlog.github.io@master/assets/img/posts/Knowledge/\AugmentedReality/KL-CE-AR1-1.png
category: Knowledge
tags:
  - Advanced
  - Computer Engineering
  - Augmented Reality
author: 안상현
---



# <span style="color:#2E64FE">ReadMe</span>

 아래 내용은 *Developer apple* 에서 제공하는 **Displaying a Point Cloud Using Scene Depth**  포스트 내용을 번역했습니다. 

# <span style="color:#2E64FE">Overview</span>

 디바이스의 LiDAR 스캐너로부터 물리적 환경 속 여러 객체에서 측정된 Point cloud는 `Depth cloud` 라는 앱에서 확인할 수 있습니다. 3D 그래픽 장치인 [Metal](https://developer.apple.com/documentation/metal)을 사용했음을 참고해주세요. 환경에서 미터 단위로 거리를 측정한 [depthMap](https://developer.apple.com/documentation/arkit/ardepthdata/3566296-depthmap)으로 물리적 환경에 가상의 객체를 그릴 수 있습니다. 최종 재구성된 포인트 클라우드와 함께 말이죠. `Depth cloud`는 ARKit의 카메라 이미지로부터 클라우드에 이미지 [capturedImage](https://developer.apple.com/documentation/arkit/arframe/2867984-capturedimage)를 씌워줍니다.
 
 모든 뎁스 맵의 연결점들(클라우드의 모든 점들)은 샘플 앱이 카메라 이미지의 관련된 픽셀들을 체크해줍니다.
그리고 점들에게 픽셀의 값을 넣어줍니다. 사용자가 포인트 클라우드를 직접 볼 때는 앱이 카메라 피드와 동일하게 나타납니다. 클라우드의 3D 형상을 증명하기 위해 샘플 앱은 유저가 회전시킬 수 있습니다.

 아래 그림은 단일 촬영을 이용한 포인트 클라우드를 보여줍니다. y 축을 기준으로 돌려졌는데 검은 영역은 깊이와 컬러 정보가 부족해서 그렇습니다.

 <img src="https://cdn.jsdelivr.net/gh/MnSBlog/MnSBlog.github.io@master/assets/img/posts/Knowledge/AugmentedReality/KL-CE-AR1-1.png" height="400px" width="650px" align="center">

 앱에서는 깊이 컨피던스 값([confidenceMap](https://developer.apple.com/documentation/arkit/ardepthdata/3566295-confidencemap))을 알 수 있습니다. 또한 앱은 뎁스버퍼를 크게 할 수도 있고 ARKit의 스무스 뎁스 옵션([smoothedSceneDepth](https://developer.apple.com/documentation/arkit/arconfiguration/framesemantics/3674208-smoothedscenedepth))도 있습니다. 사용자는 라이브 모드를 적용할 수도 있으니 여러 셋팅들을 통해서 경험을 만들어봅시다.

 ---
 - Note
 WWDC20 session 10611: Explore ARKit 4는 클라우드의 포인트들을 누적하는 이전 버전의 샘플 앱을 참조합니다. 원 버전에 관심이 있으시면 깃 레포지토리의 초기화 커밋의 루트 폴더를 참고해주세요.
 ---

 깊이 값을 이용하여 마스킹이나 안개처리를 하고싶으시면 [여기](https://developer.apple.com/documentation/arkit/environmental_analysis/creating_a_fog_effect_using_scene_depth)를 참고해주세요.

# <span style="color:#2E64FE">Set Up a Camera Feed</span>

 카메라 피드를 디스플레이하기 위하여 샘플 프로젝트는 SwiftUI [Scene](https://developer.apple.com/documentation/swiftui/scene)을 단일 윈도우가 들어간 [body](https://developer.apple.com/documentation/swiftui/view/body-swift.property)와 함께 정의합니다. 아래 코드와 함께 MetalDepthView라는 single [View](https://developer.apple.com/documentation/swiftui/view) 타입이 있습니다.

 ```swift
 @main
struct PointCloudDepthSample: App {
    var body: some Scene {
        WindowGroup {
            MetalDepthView()
 ```








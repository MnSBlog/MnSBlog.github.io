---
date: 2021-11-20 10:57:00
layout: post
title: Bayesian Decision Theory
subtitle: Understaning the Bayesian Decision Theory in Pattern Classification
description: Pattern Classfication
image: https://drive.google.com/uc?export=view&id=1yuK8wZzmEf8hrMP920y3dkRJUffOz2JS
category: Machine Learning
tags:
  - Machine Learning
  - Pattern Classification
  - Bayesian
  - Analytically method
  - Deviation
author: 안상현
---



# <span style="color:#2E64FE">Introduction</span>

`Bayesian Decision Theory` 는 `Pattern Classification` 의 문제에서 기본적이고, 통계적인 접근법입니다. 이 방법은 확률적으로 다양한 분류 결정과 결정에 동반되는 비용간 적정지점을 정량화합니다. 저희는 이 포스팅을 통해서 간단한 메소드 구동을 이해하고 확률적인 구조에 대해 알게 하겠습니다.

 대부분의 상황에서 적은 정보를 가지고 어떤 결정을 할 수 없습니다. 어느정도 구분가능한 변수를 x로 뒀을때, 이 x를 통해서 `classifier` 를 개선해 나갑니다. 2 가지 구분인 경우 `Bayesian standard form` 은 아래와 같습니다.


$$
P(\omega_j|x)=\frac{p(x|\omega_j)P(\omega_j)}{p(x)}\\
\text{Posterior}=\frac{\text{likelihood * prior}}{\text{evidence}}\\
p(x)=\sum_{j=1}^2p(x|\omega_j)P(\omega_j)
$$



#### State of Nature

`omega` 는 `State of nature` 로 표현하겠습니다. 기본적으로 `State of nature` 는 예측하기 어렵습니다. 더 상세한 예를 들자면 `omega` 가 연어라면 `omega = omega_2`, 배스라면 `omega = omega_1` 입니다. 그렇다면 `omega` 를 확률적인 접근을 통해 적절한 결정(배스인지, 연어인지)이 이뤄져야 합니다.

#### Prior

일반적으로 `priori probability` P(`omega_1`) 이랑 P(`omega_2`)가 있다고 가정하면서,  이 분포는 물고기의 서식지역, 무게, 모양, 생김새 등의 여러 변수로서 분포가 구성됩니다.

#### Posterior

위에서 언급한 x로서 조정하여 `Prior probability` 를 바꿉니다. 이는 바로 `Posteriori probability` P(`omega_j|x`)가 됩니다.

#### Likelihood

`Prior` 에서 발생한 결과가 있다면, P(`x|omega_j`)가 되겠죠. 결국은 `Posterior` 는 결과가 발생한 조건 속에서 `Prior` 이 발생할 확률이고 `Likelihood` 는 `Prior` 이 발생한 조건 속에서 `x` 가 발생할 확률입니다.

#### Evidence

`Prior Probability` 에서 x를 두어 예측합니다. 그래서 `Predictor Prior Probability` 라고 합니다.

# <span style="color:#2E64FE">Bayesian Decision Theory-Continuous Features</span>

- 하나 이상의 Feature를 사용할 것
- 두 개 이상의 States of nature를 허용한다.
- State of nature를 결정하는 것외에 다른 액션 또한 허용한다.
- error 확률보다 더 일반화된 `loss function` 을 허용한다.

위 일반화 조건들과 그에 따라오는 수식적인 복잡성은 `Bayesian Decision Theory` 에 대한 메커니즘을 헷갈리게 할 수 있습니다.

`omega` 는 유한한 집합 c에 있는 `states of nature` 이며, `alpha` 는 유한한 집합 a에 있는 `action` 입니다.

#### Feature space

기본적인 것을 깨우쳐야하죠. Feature vector x는 요소 x들을 d 만큼 가졌다고 할 때, 이를 `Feature space` 라고 부릅니다.


$$
\text{x}\in R^d, \text{x}=\{x_1,\ x_2, \dots, x_d\}
$$



#### Loss function

 또한 `loos function` 은 정확하게 액션을 비용적으로 설명할 수 있습니다. 이는 확률적으로 정해진 값을 통해 결정을 확인하여 비용으로 변환합니다.  `loss function`은 `lambda` 로 표현하며 아래와 같습니다.


$$
\lambda(\alpha_i|\omega_j)
$$


 그럼 이제 `Bayesian standard form` 을 아래처럼 표현하겠습니다.


$$
P(\omega_j|\text{x})=\frac{p(\text{x}|\omega_j)P(\omega_j)}{p(\text{x})}\\
\text{Posterior}=\frac{\text{likelihood * prior}}{\text{evidence}}\\
p(\text{x})=\sum_{j=1}^cp(\text{x}|\omega_j)P(\omega_j)
$$



#### Risk

 `expected loss` 를 `Risk` 라고 표현하며 아래와 같이 조건부 `risk` 로 얘기합니다. `observation` set x에 대해서 해당 action을 취했을 때 예상되는 `loss` 라고 할 수 있죠.


$$
R(\alpha_i|\text{x})=\sum_{j=1}^c\lambda(\alpha_i|\omega_j)P(\omega_j|\text{x})
$$



#### Decision Rule

전체적인 `risk` 를 `prior` 인 P(`omega_j`) 로서 줄인다고 한다면, 일반적인 `decision rule` 은 feasible observation을 통해 가져오는 action function인 a(x)로 말합니다. 좀 더 세부적으로 들어가서 모든 x에 대한 decision function a(x)는 존재하는 모든 action에 대해 하나만 고른다고 가정하고 `risk` R은 `decision rule` 에 대해서 계산할 수 있습니다. 그러므로 `risk` 를 `decision rule` 에 의해 표기하면 아래와 같습니다.


$$
R=\int R(\alpha(\text{x})|\text{x})p(\text{x})\ d\text{x}
$$



정리하면 `overall risk` 를 최소화 하고 `conditional risk` 를 계산합니다. 이를 통해 최고의 성능을 내는 최적 리스크를 곧 `Bayes risk` R^*로 정의합니다.

## <span style="color:#FF8080">Two-Category Classification</span>

지금까지 `terminology` 에 대하여 얘기했다면, 아까처럼 연어와 배스, 개와 고양이 같이 두 카테고리를 분류하는 것에 대하여 설명하겠습니다.


$$
R(\alpha_1|\text{x})=\lambda_{11}P(\omega_1|\text{x})+\lambda_{12}P(\omega_2|\text{x})\\
R(\alpha_2|\text{x})=\lambda_{21}P(\omega_1|\text{x})+\lambda_{22}P(\omega_2|\text{x})
$$


`omega_1` 은 아까 배스였죠. Feature space 속에서 배스가 나올 확률 , 연어가 나올 확률입니다. 1번 액션을 선택했을 때 코스트를 알 수 있죠. 위 식으로 만들어진 경우에는 R(a_1|x)가 작으면 아무래도 배스를 선택하겠죠? 적은 로스니까요. 결국 action_1이 적은 리스크를 만든다 라고 표현해도 됩니다. 그러니 `omega_1` 을 바라게 되는 꼴입니다. 그래서 이를 정리하면


$$
(\lambda_{21}-\lambda_{11})P(\omega_1|\text{x})\gt(\lambda_{12}-\lambda_{22})P(\omega_2|\text{x})
$$


좌변을 봅시다. 배스가 나올 확률에 연어라 선택해서 배스가 나오는 loss value, 배스라 선택하고 배스인 loss value의 편차를 봅니다. 어떤 액션을 선택해도 배스가 나온다면 좌변, 연어가 나온다면 우변, 그리고 `lambda` 편차가 양수라면 제대로 선택하는 것이고, 그 양수 중에서도 값이 크다면 올바른 결정을 할 수 있습니다. 현 부등식으로 보면 배스죠.

#### Likelihood ration

 `Posterior` 을 이용한 부등식을 `likelihood` 와 `Prior` 형태로 바꿔보겠습니다.


$$
(\lambda_{21}-\lambda_{11})p(\text{x}|\omega_1)P(\omega_1)\gt(\lambda_{12}-\lambda_{22})p(\text{x}|\omega_2)P(\omega_2)
$$


이를 다시 정리하면,


$$
\frac{p(\text{x}|\omega_1)}{p(\text{x}|\omega_2)}\gt\frac{\lambda_{12}-\lambda_{22}}{\lambda_{21}-\lambda_{11}}\frac{P(\omega_2)}{P(\omega_1)}
$$


`likelihood ratio` 를 기준으로 좌변이 넘어왔습니다. 이는 다음에 만들어지는 `Posterior` 를 구성하기 위해 정리된 식입니다.

# <span style="color:#2E64FE">Minimum-Error-Ratio Classification</span>

`classification` 문제에서는 각 `state of nature` 가 분류 셋 c 안의 다른 하나를 도와주고 `action`은 결정을 통해 `state of nature`  를 해석합니다. 위에서 설명한대로 올바른 액션에 대한 `loss function` 은 `zero-one loss function` 의 표현으로 할 수 있습니다.

#### Zero-One loss function


$$
\lambda(a_i|\omega_j)=
\begin{cases}
0, & i=j \\
1, & i\neq j
\end{cases}
\qquad i,\ j=1,\dots,c
$$



`Zero-One loss function` 으로부터 `Risk` 를 아래로 정리하겠습니다.


$$
\begin{array}{l}
R(\alpha_i|\text{x}) & = \underset{j=1}{\overset{c}{\sum}}\lambda(\alpha_i|\omega_j)P(\omega_j|\text{x})\\
&=\underset{j\neq i}{\sum}P(\omega_j|\text{x})\\
&=1-P(\omega_i|\text{x})
\end{array}
$$


`Risk` 는 조건부 확률인 `posterior` 의 반대 확률을 취하게 됩니다. 그러니 이젠 `posterior` 를 최대화하는 것으로 목적이 바뀌어 버립니다.

<img src="https://drive.google.com/uc?export=view&id=1dJkyIkzBJ_pYaDk1bBVgNV_BvjOPp6gJ" align="center">

위 그림은 `likelihood ratio` 를 동일한 케이스에서 보여줍니다. 보통 이 `likelihood ratio` 는 0과 무한대 사이에 존재하며 `theta` 는 `Threshold value` 입니다. `theta_a`는 `prior`에서 마크되며 `likelihood ratio` 에 의하여 `theta_b` 가 마크됩니다.  대국적으로 x축에 따른 classification 흐름으로 볼 수 있습니다.

## <span style="color:#FF8080">Minimax Criterion</span>

 `Classifier` 를 설계할 때, `prior` 에서 잘 동작하도록 하는 경우가 있습니다. 예를 들어 지금의 배스, 연어 구분을 보면, 가벼운 정도나 길이같은 물리적인 특징들은 일정함에 비해서 `prior` 은 범위도 넓고 예측할 수 없이 다양합니다. 또한 `prior` 확률을 모르는 다른 생물에도 분류기를 사용하기를 원할 수 있습니다. 그래서 합리적으로 `prior` 값에 대한 전체 `risk` 가 작도록, 가능한 전체 `risk`를 최소화하는 분류기를 설계합니다.

 그렇다면 그 중요한 전체 `risk` 는 어떻게 할 수 있냐면, `likelihood` 와 `prior`, 그리고 `loss function` 으로 알 수 있습니다.


$$
\begin{array}{l}
R &= \underset{\mathcal{R}_1}{\int}[\lambda_{11}P(\omega_1)p(\text{x}|\omega_1)+\lambda_{12}P(\omega_2)p(\text{x}|\omega_2)] \text{dx}\\
&+ \underset{\mathcal{R}_2}{\int}[\lambda_{21}P(\omega_1)p(\text{x}|\omega_1)+\lambda_{22}P(\omega_2)p(\text{x}|\omega_2)] \text{dx}
\end{array}
$$


 저희가 아까 전에 `Posterior` 를 최대화하는, 해당 수식으로 다시 재구성해보겠습니다. 그런데 `LaTex` 로는 표현이 안되어 `Pattern Classification` 원 수식을 그대로 가져왔습니다.

<img src="https://drive.google.com/uc?export=view&id=1zXaD1uJAeIwbjtDYeims8EDThOr2n6Gc" align="center">

이 텀의 의미는 하나에 대한 `Decision boundary` 와 전체 `risk` 가 선형이라는 점, minimax solution으로 0이 되는 바운더리도 있죠.

#### Minimax Risk


$$
R_{mm}=\lambda_{22}+(\lambda_{12}-\lambda_{22})\underset{R_1}{\int}p(\text{x}|\omega_2) \text{ dx}\\
=\lambda_{11}+(\lambda_{21}-\lambda_{11})\underset{R_2}{\int}p(\text{x}|\omega_1)\text{ dx}
$$



<img src="https://drive.google.com/uc?export=view&id=1pLc7l73eOM4Vj_z5Sf-DB0IJULJsi_qG" align="center">

이 그림이 의미하는 바는 아래 실선 곡선은 고정 분포의 2가지 분류 문제에서 사전 확률의 함수로써 최소(`Bayes`) 오차를 나타냅니다. `prior` 값의 각 값(P(w1)=0.25)에 대해 해당하는 최적의 결정 경계와 관련된 `Bayes error rate` 입니다. 모든 (고정된) 경계의 경우, `Prior`이 변경되면, 오류 확률은 P(w1) = 1에서 이전 값의 `Linear function` 으로 바뀝니다. 오차의 최대치를 최소화하기 위해, 우리는 최대 `Bayes error`에 대한 결정 경계를 설계해야 합니다.(P(w1)=0.6). 따라서 오류는 이전 함수처럼 변경되지 않을 것이고. 빨간색 수평선으로 표시되어 있습니다.

## <span style="color:#FF8080">Neyman-Pearson Criterion</span>

일부 문제에서는 제약의 대상이 되는 전체 `risk` 를 최소화하고자 할 수 있습니다. 예를 들어, 저희는 `Feature`에 따라 영향을 받는 전체 `Risk`을 최소화하고자 할 수 있습니다. 그러한 `Constratins`는 하나의 특정 작용에 수반되는 고정된 자원이 있거나, 제한된 빈도보다 더 많은 특정 자연 상태에서 패턴을 잘못 분류해서는 안 되는 경우에 발생할 수 있죠. 예를 들어, 연어의 1% 이상을 배스라고 잘못 분류해서는 안 된다는 정부 규제가 있을 수 있겠죠. 뭐 의료분야에서 따진다면, 암인데 아니라고 판단하는 정확도가 0.3%를 넘으면 안된다 그런 식으로요. 이런 경우라면 연어보고 배스라고 분류할 가능성에 대해 최소화하는 결정을 구해야 합니다. 즉 전략, 정책을 바꾸는 선택을 하는 것이죠.
